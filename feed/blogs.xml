<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en"><generator uri="https://jekyllrb.com/" version="4.4.1">Jekyll</generator><link href="https://leomaglanoc.github.io/feed/blogs.xml" rel="self" type="application/atom+xml"/><link href="https://leomaglanoc.github.io/" rel="alternate" type="text/html" hreflang="en"/><updated>2026-01-14T14:54:56+00:00</updated><id>https://leomaglanoc.github.io/feed/blogs.xml</id><title type="html">blank | Blogs</title><subtitle>Leonardo Maglanoc&apos;s personal website on robotics, AI, and humanoid robots. </subtitle><entry><title type="html">AI Coding Agent Case Study</title><link href="https://leomaglanoc.github.io/blog/AI-coding-agent-case-study/" rel="alternate" type="text/html" title="AI Coding Agent Case Study"/><published>2025-12-28T00:00:00+00:00</published><updated>2025-12-28T00:00:00+00:00</updated><id>https://leomaglanoc.github.io/blog/AI-coding-agent-case-study</id><content type="html" xml:base="https://leomaglanoc.github.io/blog/AI-coding-agent-case-study/"><![CDATA[<p>I’ve been experimenting with Codex, OpenAI’s coding agent (GPT-5.2-Codex with high reasoning effort). Below are two use cases I experimented with:</p> <ul> <li>Gaming WebApps</li> <li>Mathematical proof formalizers</li> </ul> <p>I ‘vibecoded’ in less than an hour without writing a single code line and having any previous experience in both areas. I additionally used ChatGPT for brainstorming. I’m amazed by the progress and capabilities of generative, agentic AI, even though they have some limitations too.</p> <ul> <li><a href="/assets/interactive/flappy/index.html">Flappy Bird</a></li> <li><a href="/assets/interactive/race/index.html">Top Down Racing Game</a></li> <li><a href="/assets/interactive/robot-runner/index.html">Jump and Run Sidescroller</a></li> </ul> <p>everything below here is written by GenAI!</p> <h3 id="a-tiny-but-useful-discrete-time-barrier-lemma--formalized-in-lean">A tiny (but useful) discrete-time barrier lemma — formalized in Lean</h3> <p>Barrier functions show up everywhere in safe AI and robotics: you define a scalar <strong>safety measure</strong> \(B(x) \le 0\) and you want to guarantee the system <strong>stays safe over time</strong>.</p> <p>In discrete time, we can phrase this in the simplest possible way:</p> <ul> <li>Let $x_k$ be a trajectory (states at time steps $k \in \mathbb{N}$).</li> <li>Let $B : \alpha \to \mathbb{R}$ be a barrier / safety score.</li> <li>Define the scalar sequence \(b_k := B(x_k).\)</li> <li>Assume the barrier score never increases: \(b_{k+1} \le b_k \quad \forall k.\)</li> <li>And assume we start safe: \(b_0 \le 0.\)</li> </ul> <p><strong>Claim (forward invariance in discrete time):</strong> \(\forall k,\quad b_k \le 0 \quad\text{(equivalently, } \forall k,\ B(x_k)\le 0\text{).}\)</p> <hr/> <h4 id="proof-idea-one-paragraph">Proof idea (one paragraph)</h4> <p>From $b_{k+1} \le b_k$, the sequence is <strong>non-increasing</strong>. By repeatedly chaining inequalities, \(b_k \le b_{k-1} \le \cdots \le b_0.\) So $b_k \le b_0$ for all $k$. Combining with $b_0 \le 0$ gives \(b_k \le 0 \quad \forall k.\) That’s it: <strong>non-increasing barrier value + safe start ⇒ always safe</strong>.</p> <hr/> <h4 id="lean-formalization">Lean formalization</h4> <p>Below is a Lean 4 proof (mathlib) that compiles and checks the argument mechanically.</p> <div class="language-lean highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">import</span> <span class="n">Mathlib</span><span class="o">.</span><span class="n">Data</span><span class="o">.</span><span class="n">Real</span><span class="o">.</span><span class="n">Basic</span>

<span class="k">theorem</span> <span class="n">barrier_discrete_scalar</span>
  (<span class="n">b</span> : <span class="o">ℕ</span> <span class="o">→</span> <span class="err">ℝ</span>)
  (<span class="n">h_step</span> : <span class="o">∀</span> <span class="n">k</span> : <span class="o">ℕ</span>,
    <span class="n">b</span> (<span class="n">k</span> <span class="o">+</span> <span class="mi">1</span>) <span class="o">≤</span> <span class="n">b</span> <span class="n">k</span>)
  (<span class="n">h0</span> : <span class="n">b</span> <span class="mi">0</span> <span class="o">≤</span> <span class="mi">0</span>) :
  <span class="o">∀</span> <span class="n">k</span> : <span class="o">ℕ</span>, <span class="n">b</span> <span class="n">k</span> <span class="o">≤</span> <span class="mi">0</span> := <span class="k">by</span>
  <span class="n">intro</span> <span class="n">k</span>

  <span class="k">have</span> <span class="n">hk0</span> : <span class="n">b</span> <span class="n">k</span> <span class="o">≤</span> <span class="n">b</span> <span class="mi">0</span> := <span class="k">by</span>
    <span class="n">induction</span> <span class="n">k</span> <span class="k">with</span>
    <span class="o">|</span> <span class="n">zero</span> <span class="o">=&gt;</span>
        <span class="n">exact</span> <span class="n">le_rfl</span>
    <span class="o">|</span> <span class="n">succ</span> <span class="n">k</span> <span class="n">ih</span> <span class="o">=&gt;</span>
        <span class="n">exact</span> <span class="n">le_trans</span> (<span class="n">h_step</span> <span class="n">k</span>) <span class="n">ih</span>

  <span class="n">exact</span> <span class="n">le_trans</span> <span class="n">hk0</span> <span class="n">h0</span>

<span class="k">theorem</span> <span class="n">barrier_discrete</span>
  (<span class="n">B</span> : α <span class="o">→</span> <span class="err">ℝ</span>)
  (<span class="n">x</span> : <span class="o">ℕ</span> <span class="o">→</span> α)
  (<span class="n">h_step</span> : <span class="o">∀</span> <span class="n">k</span> : <span class="o">ℕ</span>,
    <span class="n">B</span> (<span class="n">x</span> (<span class="n">k</span> <span class="o">+</span> <span class="mi">1</span>)) <span class="o">≤</span> <span class="n">B</span> (<span class="n">x</span> <span class="n">k</span>))
  (<span class="n">h0</span> : <span class="n">B</span> (<span class="n">x</span> <span class="mi">0</span>) <span class="o">≤</span> <span class="mi">0</span>) :
  <span class="o">∀</span> <span class="n">k</span> : <span class="o">ℕ</span>, <span class="n">B</span> (<span class="n">x</span> <span class="n">k</span>) <span class="o">≤</span> <span class="mi">0</span> := <span class="k">by</span>
  <span class="n">intro</span> <span class="n">k</span>

  <span class="n">simpa</span> <span class="k">using</span>
    (<span class="n">barrier_discrete_scalar</span>
      (<span class="n">b</span> := <span class="k">fun</span> <span class="n">k</span> <span class="o">=&gt;</span> <span class="n">B</span> (<span class="n">x</span> <span class="n">k</span>))
      <span class="n">h_step</span>
      <span class="n">h0</span>
      <span class="n">k</span>)
</code></pre></div></div>]]></content><author><name></name></author><category term="blogpost"/><category term="game"/><category term="canvas"/><category term="javascript"/><summary type="html"><![CDATA[I’ve been experimenting with Codex, OpenAI’s coding agent (GPT-5.2-Codex with high reasoning effort). Below are two use cases I experimented with:]]></summary></entry><entry><title type="html">My Research Goals</title><link href="https://leomaglanoc.github.io/blog/research-goals/" rel="alternate" type="text/html" title="My Research Goals"/><published>2025-12-17T00:00:00+00:00</published><updated>2025-12-17T00:00:00+00:00</updated><id>https://leomaglanoc.github.io/blog/research-goals</id><content type="html" xml:base="https://leomaglanoc.github.io/blog/research-goals/"><![CDATA[<p>My ultimate dream is to enable safe and reliable humanoid autonomy in human environments. I want to achieve this by tackling the following subproblems:</p> <ul> <li>Safety and reliability guarantees with safe control methods</li> <li>Unify manipulation and locomotion in one safe loco-manipulation framework</li> <li>Semantic reasoning with foundation models</li> <li>Testing safe humanoids in real-world industrial and domestic use cases.</li> </ul> <p>In parallel, I’m interested in deeper theoretical questions that may inform long-term humanoid intelligence:</p> <ul> <li>Algorithmic foundations of AI agents with neuroscience insights, e.g., continual learning with scalable brain-inspired architectures</li> <li>Mathematical theory of AI</li> </ul> <p>Overall, my research spans the full technology pipeline of intelligent humanoid systems:</p> <div class="text-center"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/pipeline-480.webp 480w,/assets/img/pipeline-800.webp 800w,/assets/img/pipeline-1400.webp 1400w," type="image/webp" sizes="95vw"/> <img src="/assets/img/pipeline.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" style=" max-width: 900px; " loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> <p>If you are interested in collaborating on any of these topics, please don’t hesitate to contact me via email or LinkedIn!</p>]]></content><author><name></name></author><category term="blogpost"/><category term="research"/><summary type="html"><![CDATA[My ultimate dream is to enable safe and reliable humanoid autonomy in human environments. I want to achieve this by tackling the following subproblems:]]></summary></entry></feed>