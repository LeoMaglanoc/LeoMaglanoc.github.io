---
title: My Mission
date: 2025-12-17
permalink: /blog/research-goals/
categories: [blogpost]
tags: [research]
---

My mission is to enable safe and reliable humanoid autonomy in human environments for the benefit of humanity, and to leave the world better than I found it.

## Near-Term Research

Recent progress with foundation models suggests that we may be close to achieving general humanoid autonomy. However, current real-world deployment will rely on human supervision, similar to safety teleoperation in autonomous driving. Despite massive long-term investments (Google has invested ~$30 billion in Waymo over the last 15 years), fully unsupervised autonomy has not been achieved.

[As Ilya Sutskever remarked](https://www.youtube.com/watch?v=aR20FWCCjAs), we're shifting from the "age of scaling" back into an "age of research". Simply investing more compute or capital is not enough. Instead, we need research on fundamental algorithmic breakthroughs.

To achieve my goals, I'm tackling the following subproblems:

- Safety and reliability guarantees with safe control methods
- Unify manipulation and locomotion in one safe loco-manipulation framework
- Semantic reasoning with foundation models
- Testing safe humanoids in real-world industrial and domestic use cases.

In parallel, I'm interested in deeper theoretical questions that may inform long-term humanoid intelligence:

- Algorithmic foundations of AI agents with neuroscience insights, e.g., continual learning with scalable brain-inspired architectures
- Mathematical theory of AI 

Overall, my work spans the full technology pipeline of intelligent humanoid systems:

<div class="text-center">
 {% include figure.liquid loading="eager" path="assets/img/pipeline.png" class="img-fluid rounded z-depth-1" max-width="900px" %}
</div>

## Long-Term Vision

Robotics & AI can be both a force for [good](https://www.darioamodei.com/essay/machines-of-loving-grace) and for [harm](https://www.darioamodei.com/essay/the-adolescence-of-technology). Already today, LLMs lower barriers to building [dangerous systems](https://red.anthropic.com/2025/biorisk/) and agentic AI can automate access to harmful resources. As AI capabilities continue to improve, these risks will increasingly extend into the physical world. 

While there are growing efforts in AI safety, physical AI safety (e.g., for autonomous robots operating in human environments) remains underdeveloped.

My long-term vision is to found a research-first robotics startup in Europe dedicated to establishing certifiable safety standards for physical AI and translating them into deployable systems for real-world use (e.g., humanoid robots, autonomous drones, and human-in-the-loop embodied systems such as brain-computer interfaces). For agentic systems, physical safety cannot be separated from semantic safety: robots must not only act within physical constraints, but also [align their behavior with human-defined norms and values](https://www.anthropic.com/news/claude-new-constitution).

Achieving this will require collaboration among academia, industry, and regulators to enable the creation of safe, value-aligned embodied AI that can be deployed responsibly in the real world.

